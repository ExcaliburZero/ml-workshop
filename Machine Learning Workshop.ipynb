{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workshop Activity\n",
    "\n",
    "Activity for the SUNY Oswego Computer Science Associationâ€™s Git Workshop. Written by Christopher Wells, and released under CC0 license.\n",
    "\n",
    "## Getting the Necessary Python Libraries\n",
    "For this workshop we will be using a few different Python libraries that are useful for applying machine learning to problems. Specifically, we willbe using the following libraries:\n",
    "\n",
    "* numpy\n",
    "* pandas\n",
    "* scikit-learn\n",
    "* matplotlib\n",
    "* seaborn\n",
    "* scikitplot\n",
    "\n",
    "You can install these libraries using `pip`. Though be sure to install them for Python 3, as this notebook uses Python 3.\n",
    "\n",
    "## Check that the Libraries are Installed\n",
    "Before we move on to the machine learning, let's first check that we have allthe needed libraries installed. Try running the cell below to see if they are all installed.\n",
    "\n",
    "You can run the cell by clicking on it and pressing `Ctrl` + `Enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scikitplot.plotters as scplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data\n",
    "The first thing we will need to do is to get the data that we want to try applying machine learning to.\n",
    "\n",
    "For this workshop we will be using the classic `iris` dataset, which a dataset of information on different types of iris flowers.\n",
    "\n",
    "Run the cell below to download the `.csv` file for the the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/pandas/tests/data/iris.csv\"\n",
    "file_name = \"iris.csv\"\n",
    "\n",
    "urllib.request.urlretrieve(url, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have downloaded the data file, we can use the `pandas` library to load it into Python.\n",
    "\n",
    "We can use the `read_csv` function in `pandas` to read the data file into a strucutre called a dataframe that we can use to work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_name)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the dataframe has 5 columns: `SepalLength`, `SepalWidth`, `PetalLength`, `PetalWidth`, and `Name`\n",
    "\n",
    "The first 4 columns are qualities of the flower, and the last column is the type of iris that the flower is.\n",
    "\n",
    "## Visualizing the Data\n",
    "Before we start applying machine learning to the data, let's try plotting some of the data to see if there is a relationship between the different qualities of the flowers and their type (`Name`).\n",
    "\n",
    "By visualizing the data, we can get an idea of what patterns the machine learning algorithms can pickup on to determine the type of an unkown iris.\n",
    "\n",
    "We can use the `matplotlib` and `seaborn` libraries to make plots of the data.\n",
    "\n",
    "Let's try plotting making a scatter plot of the `SepalLength` and `SepalWidth` and clor the points with the `Name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = \"SepalLength\"\n",
    "y = \"SepalWidth\"\n",
    "hue = \"Name\"\n",
    "\n",
    "sns.lmplot(x=x, y=y, hue=hue, truncate=True, size=6, data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that just looking at the `SepalWidth` and `SepalLength` we can visually distinguish between the `iris-seteosa` and the other categories of irises.\n",
    "\n",
    "Try making another plot of the data showing the `PetalLength` and `PetalWidth` with the points colored by `Name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have plotted the `PetalLength` and `PetalWidth` we can see that each of the different categories of irises are fairly easy to tell apart based on these two variables.\n",
    "\n",
    "So perhaps there may be some sets of variables that make it easier to distinguish between the different categories. Let's try making some plots of all the different variable combinations.\n",
    "\n",
    "Seaborn provides a nice function to automate this process called `pairplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue = \"Name\"\n",
    "\n",
    "sns.pairplot(data, hue=hue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the different plots, we can see that the blue points (`iris-setosa`) are very seperable from the red (`iris-virginica`) and green (`iris-versicolor`). Additionally the red and green points look mostly seperable, but with some overlap in each of the plots.\n",
    "\n",
    "## Applying ML for Classification\n",
    "Now that we have an idea of what the data looks like, we can try applying machine learning algorithms to it.\n",
    "\n",
    "We will try to create a classifier, which given information about an iris of an unknown type, will try to guess the type of the iris. This is known as supervised learning.\n",
    "\n",
    "In order to create the classifier and see how well it works, we will need to split our dataset into two pieces, a training set and a test set. We will train the classifier on the training set, and test how well it works on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_columns = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n",
    "y_column = \"Name\"\n",
    "\n",
    "X = data.as_matrix(X_columns)\n",
    "y = data[y_column]\n",
    "\n",
    "test_percentage = 0.66\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_percentage, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training and test sets, we can create and train a classifier on them.\n",
    "\n",
    "For now we will be using a `RandomForestClassifier`, which is a classifier model in the `scikit-learn` library which is simple and works well on most datasets.\n",
    "\n",
    "We will need to:\n",
    "\n",
    "* Create the classifier\n",
    "* Train it on the training data\n",
    "* Test/score it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the classifier got a score of about `0.93`, which means that it correctly identified about 93% of the irises in the test set.\n",
    "\n",
    "To get more information on which irises it is misclassifying we can create a confusion matrix, which plots the predicted categories versus the actual categories.\n",
    "\n",
    "Luckily the `scikitplot` library provides a handy function `plot_confusion_matrix` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "scplt.plot_confusion_matrix(y_test, y_test_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot, the diagonal indicates irises that were correctly classified, and the boxes outside of the diagonal indicate those that were incorrectly classified.\n",
    "\n",
    "We can see that some `iris-versicolor` were confused with `iris-virginica` and vice-versa. This matches up with what we saw in the visualizations, that those two categories are more difficult to distinguish from one another than the `iris-setosa` category.\n",
    "\n",
    "Try creating another classifier using a Support Vector Classifier (`sklearn.svm.SVC`) instead and see if it perfoms any better on the data. ([link](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "In addition to classifying the data, we can also try applying clustering to it as well.\n",
    "\n",
    "In clustering, you take data without any category labels and you try to figure out what different categories exist in the data. This is also known as unsupervised learning.\n",
    "\n",
    "Let's try applying `KMeans` clsutering to the data. KMeans is a simple clustering algorithm that tires to create `K` number of clusters from the data where you specify the number `K`.\n",
    "\n",
    "Though before we apply clustering to the data, we will need to scale the data to account for the columns having different ranges of values, we can do this by using a `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Know that we have scaled the data, let's try creating 2 clusters from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 2\n",
    "kmeans = KMeans(n_clusters, random_state=42)\n",
    "\n",
    "clustering = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "data[\"cluster\"] = clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our clusters, let's try plotting the data to see how the clusters look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue = \"cluster\"\n",
    "\n",
    "sns.pairplot(data, hue=hue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the two clusters appear very seperable in most of the plots. Additionally the two clusters seem to coincide with the `iris-setosa` and `iris-versicolor` + `iris-virginica` categories.\n",
    "\n",
    "Try applying KMeans clustering to the data again, but this time with 3 clusters, and put the clusters in a column called `cluster_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the 3 clusters we created are actually quite simmilar to the pre-existing categories of irises. Let's try creating a confusion matrix to see how well the clusters line up with the known categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = [str(i) for i in data[\"cluster_2\"]]\n",
    "\n",
    "true_labels = data[\"Name\"].unique()\n",
    "cluster_labels = np.unique(clustering)\n",
    "\n",
    "scplt.plot_confusion_matrix(y, clustering, true_labels=true_labels, pred_labels=cluster_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each of the clusters lines up fairly well with a known category. This shows us that the known categories seem to accurately reflect groupings of iris qualities.\n",
    "\n",
    "## Resources\n",
    "\n",
    "* [Scikit-learn User Guide](http://scikit-learn.org/stable/user_guide.html)\n",
    "* [Seaborn Tutorials](http://seaborn.pydata.org/tutorial.html)\n",
    "* [Pandas Cheat Sheet](https://github.com/pandas-dev/pandas/raw/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
